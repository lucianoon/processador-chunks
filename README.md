# Processador de Chunks - Text & PDF Chunking Tool

[![Python](https://img.shields.io/badge/Python-3.7+-blue.svg)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Uma ferramenta robusta para dividir textos longos e documentos PDF em chunks menores, otimizada para processamento por sistemas de IA e RAG (Retrieval-Augmented Generation).

## âœ¨ CaracterÃ­sticas

- **Chunking baseado em tokens**: Usa tokenizers do Hugging Face para controle preciso de tamanho
- **Suporte a PDF**: ExtraÃ§Ã£o automÃ¡tica de texto de arquivos PDF
- **SobreposiÃ§Ã£o configurÃ¡vel**: MantÃ©m contexto entre chunks consecutivos
- **Tratamento de erros**: Logging detalhado e validaÃ§Ãµes robustas
- **Flexibilidade**: ParÃ¢metros totalmente configurÃ¡veis
- **Performance**: Processamento eficiente para textos grandes

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.7 ou superior
- Conta no Hugging Face (para download de modelos)

### InstalaÃ§Ã£o das dependÃªncias

```bash
# Instalar dependÃªncias principais
pip install transformers torch

# Para suporte a PDF (opcional, mas recomendado)
pip install pdfplumber

# Para desenvolvimento (opcional)
pip install pytest black flake8
```

## ğŸ“– Uso

### Chunking BÃ¡sico de Texto

```python
from extraction import simple_text_chunker

# Texto de exemplo
texto = """
Seu texto longo aqui. A ferramenta irÃ¡ dividir automaticamente
em chunks menores baseados no nÃºmero de tokens.
"""

# Criar chunks
chunks = simple_text_chunker(
    text=texto,
    max_tokens=300,      # MÃ¡ximo de tokens por chunk
    overlap=20          # SobreposiÃ§Ã£o entre chunks
)

# Cada chunk contÃ©m metadados detalhados
for chunk in chunks:
    print(f"Tokens: {chunk['tokens']}")
    print(f"Texto: {chunk['text'][:100]}...")
```

### Processamento de PDF

```python
from extraction import chunk_pdf

# Processar PDF completo
chunks = chunk_pdf(
    pdf_path="documento.pdf",
    max_tokens=512,
    overlap=50
)

print(f"PDF dividido em {len(chunks)} chunks")
```

### Exemplo Completo

```python
# Executar o arquivo principal para ver demonstraÃ§Ã£o
python extraction.py
```

## ğŸ”§ API

### `simple_text_chunker(text, embed_model, max_tokens, overlap)`

Divide texto em chunks baseados em tokens.

**ParÃ¢metros:**
- `text` (str): Texto a ser dividido
- `embed_model` (str): Modelo do tokenizer (padrÃ£o: "sentence-transformers/all-MiniLM-L6-v2")
- `max_tokens` (int): MÃ¡ximo de tokens por chunk (padrÃ£o: 300)
- `overlap` (int): Tokens de sobreposiÃ§Ã£o (padrÃ£o: 20)

**Retorno:** Lista de dicionÃ¡rios com:
- `text`: Texto do chunk
- `tokens`: NÃºmero de tokens
- `start_token`/`end_token`: PosiÃ§Ãµes dos tokens
- `start_char`/`end_char`: PosiÃ§Ãµes de caracteres
- `chunk_id`: ID sequencial do chunk

### `extract_text_from_pdf(pdf_path)`

Extrai texto de um arquivo PDF.

**ParÃ¢metros:**
- `pdf_path` (str): Caminho para o arquivo PDF

**Retorno:** String com texto extraÃ­do

### `chunk_pdf(pdf_path, embed_model, max_tokens, overlap)`

Processa PDF completo: extrai texto e divide em chunks.

**ParÃ¢metros:** Combinados dos mÃ©todos acima

**Retorno:** Lista de chunks (mesmo formato de `simple_text_chunker`)

## âš™ï¸ ConfiguraÃ§Ã£o

### Modelos de Tokenizer

A ferramenta suporta qualquer modelo do Hugging Face:

```python
# Modelo multilÃ­ngue
chunks = simple_text_chunker(text, embed_model="bert-base-multilingual-cased")

# Modelo especÃ­fico para portuguÃªs
chunks = simple_text_chunker(text, embed_model="neuralmind/bert-base-portuguese-cased")
```

### OtimizaÃ§Ã£o de Performance

Para textos muito grandes:
- Ajuste `max_tokens` conforme limite do seu modelo de IA
- Use sobreposiÃ§Ã£o menor para reduzir redundÃ¢ncia
- Considere processamento em lotes para PDFs grandes

## ğŸ§ª Testes

```bash
# Executar testes
pytest

# Verificar qualidade do cÃ³digo
flake8 extraction.py
black extraction.py
```

## ğŸ“‹ LimitaÃ§Ãµes

- PDFs com imagens ou tabelas complexas podem ter extraÃ§Ã£o de texto limitada
- Desempenho depende da velocidade de download do modelo tokenizer
- MemÃ³ria limitada para textos extremamente grandes (>100MB)

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para detalhes.

## ğŸ™ Agradecimentos

- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) - Para tokenization
- [pdfplumber](https://github.com/jsvine/pdfplumber) - Para extraÃ§Ã£o de PDF
- [Sentence Transformers](https://www.sbert.net/) - Para modelos de embedding

## ğŸ“ Suporte

Para dÃºvidas ou sugestÃµes:
- Abra uma issue no GitHub
- Email: lucianomevam@outlook.com
